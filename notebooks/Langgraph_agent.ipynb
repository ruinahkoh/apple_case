{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "861d82eb-d586-44f1-9378-59ba3e6f0b8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import StateGraph, END\n",
    "from typing import TypedDict, Annotated\n",
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "from langchain_core.messages import AnyMessage, SystemMessage, HumanMessage, ToolMessage\n",
    "from langchain_community.chat_models import ChatOpenAI\n",
    "from langchain import PromptTemplate\n",
    "from langchain.chat_models import init_chat_model\n",
    "from langchain_chroma import Chroma\n",
    "from langgraph.checkpoint.sqlite import SqliteSaver\n",
    "from langchain.chains import ConversationalRetrievalChain, RetrievalQA\n",
    "from langchain_core.tools import Tool\n",
    "# you can you other types of database like postgres rather than in memeory\n",
    "import sys\n",
    "import os\n",
    "import operator\n",
    "import numpy\n",
    "# Add parent directory to sys.path\n",
    "parent_dir = os.path.abspath(os.path.join(os.path.dirname('apple_case'), '..'))\n",
    "sys.path.insert(0, parent_dir)\n",
    "# from dotenv import load_dotenv\n",
    "import json\n",
    "# _ = load_dotenv()\n",
    "from src.utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "82f07cde-e3e1-4860-bc6b-4a83765e2d33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the path to config.json\n",
    "config_path = os.path.join(parent_dir, 'src', 'config.json')\n",
    "\n",
    "with open(config_path, 'r') as f:\n",
    "    config = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7872f423-84c2-4aa4-a6f8-3eaa2c538251",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AgentState(TypedDict):\n",
    "    messages: Annotated[list[AnyMessage], operator.add]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a0a75a78-0df3-4a7b-9d2e-53c2310a1ddb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "model_name = \"sentence-transformers/all-mpnet-base-v2\"\n",
    "model_kwargs = {'device': 'cpu'}\n",
    "encode_kwargs = {'normalize_embeddings': False}\n",
    "embeddings = HuggingFaceEmbeddings(\n",
    "            model_name=model_name,\n",
    "            model_kwargs=model_kwargs,\n",
    "            encode_kwargs=encode_kwargs\n",
    "        )\n",
    "\n",
    "\n",
    "  # #Place vectorDB under /tmp. It can be anywhere else\n",
    "# # from langchain.vectorstores import Chroma\n",
    "persist_directory = config[\"vectorstore\"][\"persist_directory\"]\n",
    "products_collection_name = config[\"vectorstore\"][\"products_collection_name\"]  \n",
    "vectordb = Chroma(collection_name=products_collection_name, embedding_function=embeddings,\n",
    "                            persist_directory=persist_directory)\n",
    "\n",
    "\n",
    "print(vectordb._collection.count())\n",
    "\n",
    "education_collection_name = config[\"vectorstore\"][\"education_collection_name\"]  \n",
    "education_vectordb = Chroma(collection_name=education_collection_name, embedding_function=embeddings,\n",
    "                            persist_directory=persist_directory)\n",
    "\n",
    "inventory_collection_name = config[\"vectorstore\"][\"inventory_collection_name\"]  \n",
    "inventory_vectordb = Chroma(collection_name=inventory_collection_name, embedding_function=embeddings,\n",
    "                            persist_directory=persist_directory)\n",
    "\n",
    "\n",
    "# # Initialize ChatOpenAI\n",
    "# model_name = \"gpt-4o-mini\"\n",
    "# llm = ChatOpenAI(model_name=model_name)\n",
    "\n",
    "# # define prompts\n",
    "# prompt = PromptTemplate(template=products_template, input_variables=[\"context\", \"question\"])\n",
    "prompt2 = PromptTemplate(template=education_template, input_variables=[\"context\", \"question\"])\n",
    "prompt3 = PromptTemplate(template=inventory_template, input_variables=[\"context\", \"question\"])\n",
    "\n",
    "     \n",
    "      \n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "09f3bcd4-5d47-4e45-a79a-287bcc2e3855",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Agent:\n",
    "    def __init__(self, model, checkpointer, system=\"\"):\n",
    "        self.system = system\n",
    "        graph = StateGraph(AgentState)\n",
    "        graph.add_node(\"llm\", self.call_openai)\n",
    "        graph.add_node(\"action\", self.take_action)\n",
    "        graph.add_conditional_edges(\"llm\", self.exists_action, {True: \"action\", False: END})\n",
    "        graph.add_edge(\"action\", \"llm\")\n",
    "        graph.set_entry_point(\"llm\")\n",
    "        self.graph = graph.compile(checkpointer=checkpointer)\n",
    "        self.model = model\n",
    "        \n",
    "        self.education_chain = RetrievalQA.from_chain_type(\n",
    "            self.model, retriever=education_vectordb.as_retriever(), chain_type_kwargs={\"prompt\": prompt2}\n",
    "        )\n",
    "\n",
    "        self.inventory_chain = RetrievalQA.from_chain_type(\n",
    "            self.model, retriever=inventory_vectordb.as_retriever(), chain_type_kwargs={\"prompt\": prompt3\n",
    "            }\n",
    "        )\n",
    "\n",
    "        #      # Define tools properly\n",
    "        tools = [\n",
    "            # Tool(\n",
    "            #     name=\"Apple Sales Assistant\",\n",
    "            #     func=self.rag_chain.run,\n",
    "            #     description=\"useful for answering questions about apple products recommendations including pricing, tech specs and descriptions.\"\n",
    "            # ),\n",
    "            Tool(\n",
    "                name=\"apple_education_assistant\",\n",
    "                func=self.education_chain.run,\n",
    "                description=\"useful for answering questions about how and where to buy Apple products.\"\n",
    "            ),\n",
    "            Tool(\n",
    "                name=\"apple_inventory_assistant\",\n",
    "                func=self.inventory_chain.run,\n",
    "                description=\"useful for checking on the inventory of products.\"\n",
    "            ),\n",
    "        ]\n",
    "\n",
    "       \n",
    "        self.tools = {tool.name: tool for tool in tools}\n",
    "        self.model = model.bind_tools(tools)\n",
    "\n",
    "   \n",
    "       \n",
    "\n",
    "    def call_openai(self, state: AgentState):\n",
    "        messages = state['messages']\n",
    "        if self.system:\n",
    "            messages = [SystemMessage(content=self.system)] + messages\n",
    "        message = self.model.invoke(messages)\n",
    "        return {'messages': [message]}\n",
    "\n",
    "    def exists_action(self, state: AgentState):\n",
    "        result = state['messages'][-1]\n",
    "        return len(result.tool_calls) > 0\n",
    "\n",
    "    def take_action(self, state: AgentState):\n",
    "        tool_calls = state['messages'][-1].tool_calls\n",
    "        tool_messages = []\n",
    "    \n",
    "        for t in tool_calls:\n",
    "            tool_name = t['name']\n",
    "            tool_args = t['args']\n",
    "            tool_call_id = t['id']\n",
    "    \n",
    "            print(f\"Calling tool: {tool_name} with args: {tool_args}\")\n",
    "    \n",
    "            result = self.tools[tool_name].invoke(tool_args)\n",
    "    \n",
    "            tool_messages.append(ToolMessage(tool_call_id=tool_call_id, name=tool_name, content=str(result)))\n",
    "    \n",
    "        return {'messages': tool_messages}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3ae54ae1-6569-417a-af19-2930b3154721",
   "metadata": {},
   "outputs": [],
   "source": [
    "def echo_tool_fn(input: str) -> str:\n",
    "    return f\"You said: {input}\"\n",
    "\n",
    "tool = Tool.from_function(\n",
    "    func=echo_tool_fn,\n",
    "    name=\"echo\",\n",
    "    description=\"Echoes what the user says.\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d5d99a65-5eb7-426e-8a88-2b8cb56f9e57",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.checkpoint.sqlite import SqliteSaver\n",
    "import sqlite3\n",
    "# you can you other types of database like postgres rather than in memeory\n",
    "conn = sqlite3.connect(\":memory:\", check_same_thread=False)  \n",
    "memory = SqliteSaver(conn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9fbeb52a-5f3f-4764-895a-4f298c066f9d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langgraph.checkpoint.sqlite.SqliteSaver at 0x7f7fd1bddee0>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2474eace-eb11-472a-911d-bcfef2148f5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"\"\"You are a Apple store assistant. Use the apple education assistant for answering about product buying strategies or where to buy apple products, or use the apple inventory assistant for shopping queries. \\\n",
    "You are allowed to make multiple calls (either together or in sequence). \\\n",
    "Only look up information when you are sure of what you want. \\\n",
    "If you need to look up some information before asking a follow up question, you are allowed to do that!\n",
    "\"\"\"\n",
    "# model = ChatOpenAI(model=\"gpt-4o-mini\")\n",
    "\n",
    "model = init_chat_model(\"gpt-4o-mini\", model_provider=\"openai\")\n",
    "abot = Agent(model,  checkpointer=memory, system=prompt)\n",
    "# agent = model.bind_tools([tool])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "29ff7865-b204-49d0-854a-d0f54903d73c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'apple_education_assistant': Tool(name='apple_education_assistant', description='useful for answering questions about how and where to buy Apple products.', func=<bound method Chain.run of RetrievalQA(verbose=False, combine_documents_chain=StuffDocumentsChain(verbose=False, llm_chain=LLMChain(verbose=False, prompt=PromptTemplate(input_variables=['context', 'question'], input_types={}, partial_variables={}, template=\"\\nYou are an Apple products educator, users will ask you questions on how to get the best deals for apple products or comparisons between different products. Use the following piece of context to answer the question.\\n\\nOnly answer questions related to product comparisons and specifications, buying strategies, deals and discounts.\\nIf you don't know the answer, just say you don't know.\\n\\nKeep your replies concise and limited to 4 sentences. \\n\\nContext: {context}\\nQuestion: {question}\\nAnswer:\\n\"), llm=ChatOpenAI(client=<openai.resources.chat.completions.completions.Completions object at 0x7f7fd1bdd370>, async_client=<openai.resources.chat.completions.completions.AsyncCompletions object at 0x7f7fcbdcb1c0>, root_client=<openai.OpenAI object at 0x7f7fcbd47a00>, root_async_client=<openai.AsyncOpenAI object at 0x7f7fcbdcb5e0>, model_name='gpt-4o-mini', model_kwargs={}, openai_api_key=SecretStr('**********')), output_parser=StrOutputParser(), llm_kwargs={}), document_prompt=PromptTemplate(input_variables=['page_content'], input_types={}, partial_variables={}, template='{page_content}'), document_variable_name='context'), retriever=VectorStoreRetriever(tags=['Chroma', 'HuggingFaceEmbeddings'], vectorstore=<langchain_chroma.vectorstores.Chroma object at 0x7f7fe10cc700>, search_kwargs={}))>),\n",
       " 'apple_inventory_assistant': Tool(name='apple_inventory_assistant', description='useful for checking on the inventory of products.', func=<bound method Chain.run of RetrievalQA(verbose=False, combine_documents_chain=StuffDocumentsChain(verbose=False, llm_chain=LLMChain(verbose=False, prompt=PromptTemplate(input_variables=['context', 'question'], input_types={}, partial_variables={}, template=\"\\nYou are an Apple store sales assistant. Users will ask you questions about Apple products and you will make recommendations on what apple product suit them based on their budget or preferences.\\nAsk for specifications of their preferences if they have not provided it.\\nYou should check the inventory and only recommend products which are in stock. Do not tell the customer the amount of stock, just whether it is in stock or not.\\n\\nA general rule of thumb when recommending products under a certain budget (150-200) you can recommend accessories\\n\\nOffer the customer a link to purchase it if it is in stock\\nOnly use the context to answer. If you don't know the answer, just say you don't know.\\n\\nKeep your replies concise and limited to 5 sentences and include the link. \\n\\nContext: {context}\\nQuestion: {question}\\nAnswer:\\n\"), llm=ChatOpenAI(client=<openai.resources.chat.completions.completions.Completions object at 0x7f7fd1bdd370>, async_client=<openai.resources.chat.completions.completions.AsyncCompletions object at 0x7f7fcbdcb1c0>, root_client=<openai.OpenAI object at 0x7f7fcbd47a00>, root_async_client=<openai.AsyncOpenAI object at 0x7f7fcbdcb5e0>, model_name='gpt-4o-mini', model_kwargs={}, openai_api_key=SecretStr('**********')), output_parser=StrOutputParser(), llm_kwargs={}), document_prompt=PromptTemplate(input_variables=['page_content'], input_types={}, partial_variables={}, template='{page_content}'), document_variable_name='context'), retriever=VectorStoreRetriever(tags=['Chroma', 'HuggingFaceEmbeddings'], vectorstore=<langchain_chroma.vectorstores.Chroma object at 0x7f7fe10cc6a0>, search_kwargs={}))>)}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "abot.tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a243ee28-eb89-4a18-90b7-adc98078037c",
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = [HumanMessage(content=\"Do you have iphones in stock\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "456850bf-ac79-45ae-9d1c-f8709ab7c7fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'messages': [AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_SWMNsK8JKnrSGVXKIX9LDiRb', 'function': {'arguments': '{\"__arg1\":\"iphone\"}', 'name': 'apple_inventory_assistant'}, 'type': 'function'}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 18, 'prompt_tokens': 183, 'total_tokens': 201, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_34a54ae93c', 'id': 'chatcmpl-BmuHRGx5pQlnvr4vOKTeIX2BlS4rw', 'service_tier': 'default', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run--90d8a872-e7cb-4c03-a990-4ba7ad845351-0', tool_calls=[{'name': 'apple_inventory_assistant', 'args': {'__arg1': 'iphone'}, 'id': 'call_SWMNsK8JKnrSGVXKIX9LDiRb', 'type': 'tool_call'}], usage_metadata={'input_tokens': 183, 'output_tokens': 18, 'total_tokens': 201, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})]}\n",
      "Calling tool: apple_inventory_assistant with args: {'__arg1': 'iphone'}\n",
      "{'messages': [ToolMessage(content='Could you tell me more about your preferences for an iPhone? For example, do you have a specific model in mind or any particular features you need? Additionally, what is your budget? This will help me recommend the best option for you.', name='apple_inventory_assistant', tool_call_id='call_SWMNsK8JKnrSGVXKIX9LDiRb')]}\n",
      "{'messages': [AIMessage(content='Could you please tell me which specific iPhone model you are interested in or any features you are looking for? Knowing your preferences will help me assist you better!', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 33, 'prompt_tokens': 260, 'total_tokens': 293, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_34a54ae93c', 'id': 'chatcmpl-BmuHWwijPG1K1bSPEaLMQt2DTrLEE', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='run--3cac3e3d-453a-4122-902e-921d0af6d3c3-0', usage_metadata={'input_tokens': 260, 'output_tokens': 33, 'total_tokens': 293, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})]}\n"
     ]
    }
   ],
   "source": [
    "thread = {\"configurable\": {\"thread_id\": \"2\"}}\n",
    "for event in abot.graph.stream({\"messages\": messages}, thread):\n",
    "    for v in event.values():\n",
    "        print(v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5ddfbd9-43ae-4bc3-abb0-94dd8be00392",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
